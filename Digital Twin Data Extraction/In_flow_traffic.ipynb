{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "\n",
    "from datetime import datetime       \n",
    "from environment import dh, pio_renderer\n",
    "from importlib.metadata import version\n",
    "from scipy.interpolate import UnivariateSpline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pio_renderer is not None:    \n",
    "    pio.renderers.default = pio_renderer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = \"AreaVerde\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE; To load the data from the Digital Hub the version of the Digital Hub must be 0.8.1    \n",
    "version('digitalhub')       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========\n",
    "# Load data\n",
    "# ===========\n",
    "project = dh.get_or_create_project(PROJECT_NAME)\n",
    "\n",
    "gates = project.get_dataitem(\"gates\").as_df()\n",
    "data = project.get_dataitem(\"gate_data\").as_df()\n",
    "\n",
    "# Join coordinates\n",
    "gate_data = pd.merge(data, gates, on=\"gate\", how=\"left\", validate=\"many_to_one\").drop(columns=[\"ID\", \"Indirizzo\", \"Settore\", \"Link google maps\"])\n",
    "# reconvert string to datetime\n",
    "gate_data[\"Data\"] = pd.to_datetime(gate_data[\"Data\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Gate Similarity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_total_vehicle = gate_data[[\"Data\", \"gate\", \"count\"]].groupby([\"Data\", \"gate\"], as_index=False).sum()\n",
    "hourly_total_vehicle = hourly_total_vehicle.pivot_table(index=\"Data\", columns=\"gate\", values=\"count\", fill_value=0).astype(int)\n",
    "average_hourly_vehicle_flow = hourly_total_vehicle.groupby(hourly_total_vehicle.index.hour).mean().astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the gates that we do not have data for the selected period.\n",
    "problematic_gates = [\n",
    "    'Colombo', 'Della Pietra', 'Di Vittorio',\n",
    "    'San Mamolo', 'Terrapieno', 'Togliatti', 'Toscana'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problematic_hourly_vehicle_flow = average_hourly_vehicle_flow[problematic_gates]\n",
    "\n",
    "# removed problematic gates and we are going to use this data as a reference\n",
    "average_hourly_vehicle_flow_ref = average_hourly_vehicle_flow.drop(columns=problematic_gates)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "similarity = {}\n",
    "df_data = []\n",
    "\n",
    "n_problematic = len(problematic_hourly_vehicle_flow.columns)\n",
    "n_ok = len(average_hourly_vehicle_flow_ref.columns)\n",
    "mat_distances = np.zeros(shape=(n_problematic, n_ok))\n",
    "i = 0\n",
    "\n",
    "\n",
    "for problematic_gate in problematic_hourly_vehicle_flow.columns:\n",
    "    gate_distances = []\n",
    "    \n",
    "    j = 0\n",
    "    for gate in average_hourly_vehicle_flow_ref.columns:\n",
    "        gate_vector = average_hourly_vehicle_flow_ref[gate].values\n",
    "        problematic_gate_vector = problematic_hourly_vehicle_flow[problematic_gate].values\n",
    "        dist = euclidean(gate_vector, problematic_gate_vector)\n",
    "        gate_distances.append((gate, dist))\n",
    "\n",
    "        mat_distances[i,j] = dist\n",
    "        j += 1\n",
    "    \n",
    "    min_distance_gate = min(gate_distances, key=lambda x: x[1])\n",
    "    similarity[problematic_gate] = min_distance_gate[0]\n",
    "    df_data.append([problematic_gate, min_distance_gate[0], min_distance_gate[1]])\n",
    "\n",
    "    i += 1\n",
    "\n",
    "min_distances_df = pd.DataFrame(df_data, columns=['Problematic Gate', 'Reference Gate', 'Euclidean Distance'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#See the minimum distances\n",
    "min_distances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the heatmap of all the distances\n",
    "import seaborn as sns\n",
    "sns.heatmap(mat_distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **In-flow Estimation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============\n",
    "# Filter dates\n",
    "# ============\n",
    "start_date = datetime(2024,6,1)\n",
    "end_date = datetime(2024,7,31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_total_vehicle = gate_data[[\"Data\", \"gate\", \"count\"]].groupby([\"Data\", \"gate\"], as_index=False).sum()\n",
    "hourly_total_vehicle = hourly_total_vehicle.pivot_table(index=\"Data\", columns=\"gate\", values=\"count\", fill_value=0).astype(int)\n",
    "hourly_vehicle_data = hourly_total_vehicle[start_date:end_date]\n",
    "average_hourly_vehicle_flow = hourly_vehicle_data.groupby(hourly_vehicle_data.index.hour).mean().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE:we do not have data for selected time for some gates.\n",
    "(average_hourly_vehicle_flow==0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_missing_gate(df, similar_gates, smoothness=1.5):\n",
    "    time = np.arange(0, 24, 1)\n",
    "    for target_gate, source_gate in similar_gates.items():\n",
    "        data = df[source_gate].values.flatten()\n",
    "        spline = UnivariateSpline(time, data, s=smoothness)\n",
    "        df[target_gate] = spline(time)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# we need to extract data for every 5 min\n",
    "# =========================================\n",
    "def extend_to_5min(df):\n",
    "    to_extract = df.copy()\n",
    "    to_extract[24] = to_extract[0]\n",
    "    to_extract.index = to_extract.index*12\n",
    "    to_extract = to_extract.reindex(range(12*24+1)).interpolate(method='quadratic')\n",
    "    if to_extract.min() < 0:\n",
    "        to_extract = to_extract - to_extract.min()\n",
    "    to_extract = to_extract /12\n",
    "    to_extract = to_extract[:-1]\n",
    "    \n",
    "    return to_extract.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping of gates with missing values as a key to their similar gates as values.\n",
    "# This similarity is based on the pattern of vehicle flow throughout the day beyond the date range we considered above.\n",
    "predicted_average_hourly_vehicle_flow = predict_missing_gate(average_hourly_vehicle_flow,similarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_hourly_vehicle_flow_filtered = predicted_average_hourly_vehicle_flow.astype(int)\n",
    "average_hourly_vehicle_flow_filtered_sumed = average_hourly_vehicle_flow_filtered.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================\n",
    "# Plotting the avereged in-flow traffic \n",
    "# ======================================\n",
    "total_flow = extend_to_5min(average_hourly_vehicle_flow_filtered_sumed)\n",
    "\n",
    "fig = px.line(total_flow)\n",
    "fig.update_layout(\n",
    "    xaxis=dict(\n",
    "        dtick=10\n",
    "    )\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "holiday_list = ['2024-01-01', '2024-01-06', '2024-03-31', '2024-04-01',\n",
    "                '2024-04-25', '2024-05-01', '2024-06-02', '2024-08-15',\n",
    "                '2024-11-01', '2024-12-08', '2024-12-25', '2024-12-26']\n",
    "\n",
    "holidays = pd.to_datetime(holiday_list).date\n",
    "hourly_vehicle = hourly_vehicle_data.reset_index()\n",
    "hourly_vehicle['Data'] = pd.to_datetime(hourly_vehicle['Data'])\n",
    "hourly_vehicle['Hour'] = hourly_vehicle['Data'].dt.hour\n",
    "\n",
    "hourly_vehicle['DayType'] = 'Weekday' \n",
    "hourly_vehicle.loc[hourly_vehicle['Data'].dt.weekday == 5, 'DayType'] = 'Saturday'  \n",
    "hourly_vehicle.loc[hourly_vehicle['Data'].dt.weekday == 6, 'DayType'] = 'Sunday' \n",
    "hourly_vehicle.loc[hourly_vehicle['Data'].dt.date.isin(holidays), 'DayType'] = 'Holiday'  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "day_types = ['Weekday', 'Saturday', 'Sunday', 'Holiday']\n",
    "plot_df = pd.DataFrame()\n",
    "flows_by_day = {}\n",
    "\n",
    "for day in day_types:\n",
    "    day_data = hourly_vehicle[hourly_vehicle['DayType'] == day]\n",
    "    numeric_columns = hourly_vehicle.columns.difference(['Data', 'Hour', 'DayType'])\n",
    "    hourly_avg = day_data.groupby('Hour')[numeric_columns].mean().astype(int)\n",
    "    predicted_hourly_avg = predict_missing_gate(hourly_avg, similarity)\n",
    "    to_extract = pd.Series(\n",
    "    extend_to_5min(predicted_hourly_avg.sum(axis=1)),\n",
    "    index=range(0, 12 * 24)\n",
    "    )\n",
    "    flows_by_day[day] = to_extract\n",
    "    df = pd.DataFrame({         \n",
    "        \"Minute\": to_extract.index,\n",
    "        \"Flow\": to_extract.values,\n",
    "        \"DayType\": day\n",
    "    })\n",
    "\n",
    "    plot_df = pd.concat([plot_df, df], ignore_index=True)\n",
    "\n",
    "fig = px.line(plot_df, x='Minute', y='Flow', color='DayType', title='Traffic Flow by Day Type')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_flow = (5/7) * flows_by_day['Weekday'] + (1/7) * flows_by_day['Saturday'] + (1/7) * flows_by_day['Holiday']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "x = list(range(0, 12 * 24))  \n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=x, y=flows_by_day['Weekday'], mode='lines', name='Weekday'))\n",
    "fig.add_trace(go.Scatter(x=x, y=flows_by_day['Saturday'], mode='lines', name='Saturday'))\n",
    "fig.add_trace(go.Scatter(x=x, y=flows_by_day['Holiday'], mode='lines', name='Holiday'))\n",
    "fig.add_trace(go.Scatter(x=x, y=total_flow, mode='lines', name='total_flow'))\n",
    "fig.add_trace(go.Scatter(x=x, y=combined_flow, mode='lines', name='WeightedAvg', line=dict(dash='dash')))\n",
    "\n",
    "fig.update_layout(title='Traffic Flow Comparison', xaxis_title='5-min Intervals', yaxis_title='Flow')\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
